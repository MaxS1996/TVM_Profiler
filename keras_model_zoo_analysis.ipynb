{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc829f5-3c92-4650-8b6b-343ac5885876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03bd027-795e-4f2a-8ed6-da54161da29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = {}\n",
    "sep_conv = {}\n",
    "dense = {}\n",
    "max_pool = {}\n",
    "avg_pool = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280a6b68-3308-4f96-b63e-2031cb36cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Xception\": keras.applications.Xception,\n",
    "    \"VGG16\": keras.applications.VGG16,\n",
    "    \"VGG19\": keras.applications.VGG19,\n",
    "    \"ResNet50\": keras.applications.ResNet50,\n",
    "    \"ResNet101\": keras.applications.ResNet101,\n",
    "    \"ResNet152\": keras.applications.ResNet152,\n",
    "    \"ResNet50V2\": keras.applications.ResNet50V2,\n",
    "    \"ResNet101V2\": keras.applications.ResNet101V2,\n",
    "    \"ResNet152V2\": keras.applications.ResNet152V2,\n",
    "    \"InceptionV3\": keras.applications.InceptionV3,\n",
    "    \"InceptionResNetV2\": keras.applications.InceptionResNetV2,\n",
    "    \"MobileNet\": keras.applications.MobileNet,\n",
    "    \"MobileNetV2\": keras.applications.MobileNetV2,\n",
    "    \"DenseNet121\": keras.applications.DenseNet121,\n",
    "    \"DenseNet169\": keras.applications.DenseNet169,\n",
    "    \"DenseNet201\": keras.applications.DenseNet201,\n",
    "    \"NASNetMobile\": keras.applications.NASNetMobile,\n",
    "    \"NASNetLarge\": keras.applications.NASNetLarge,\n",
    "    \"EfficientNetB0\": keras.applications.EfficientNetB0,\n",
    "    \"EfficientNetB1\": keras.applications.EfficientNetB1,\n",
    "    \"EfficientNetB2\": keras.applications.EfficientNetB2,\n",
    "    \"EfficientNetB3\": keras.applications.EfficientNetB3,\n",
    "    \"EfficientNetB4\": keras.applications.EfficientNetB4,\n",
    "    \"EfficientNetB5\": keras.applications.EfficientNetB5,\n",
    "    \"EfficientNetB6\": keras.applications.EfficientNetB6,\n",
    "    \"EfficientNetB7\": keras.applications.EfficientNetB7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa85772-5028-4f56-84f3-5126002c904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:47:48.213247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.213644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.244549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.244936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.245284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.245615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.246491: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-14 11:47:48.340490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.340774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.340969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.341148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.341323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.341495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.958946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4839 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:01:00.0, compute capability: 5.2\n",
      "2022-02-14 11:47:48.959182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 11:47:48.959330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5354 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:02:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception\n",
      "vgg16\n",
      "vgg19\n",
      "resnet50\n",
      "resnet101\n",
      "resnet152\n",
      "resnet50v2\n",
      "resnet101v2\n",
      "resnet152v2\n",
      "inception_v3\n",
      "inception_resnet_v2\n",
      "mobilenet_1.00_224\n",
      "mobilenetv2_1.00_224\n",
      "densenet121\n",
      "densenet169\n",
      "densenet201\n",
      "NASNet\n",
      "NASNet\n",
      "efficientnetb0\n",
      "efficientnetb1\n",
      "efficientnetb2\n",
      "efficientnetb3\n",
      "efficientnetb4\n",
      "efficientnetb5\n",
      "efficientnetb6\n",
      "efficientnetb7\n"
     ]
    }
   ],
   "source": [
    "unknown = {}\n",
    "for name, function in models.items():\n",
    "    if \"DenseNet\" in name or \"NASNet\" in name:\n",
    "        model = function(\n",
    "            include_top=True,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=1000,\n",
    "        )\n",
    "    else:\n",
    "        model = function(\n",
    "            include_top=True,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=1000,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )\n",
    "    print(model.name)\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        #print(idx)\n",
    "        if isinstance(layer, keras.layers.Conv2D):\n",
    "            conv[model.name+\":\"+layer.name] = {\n",
    "                \"filters\": layer.filters,\n",
    "                \"kernel\": layer.kernel_size,\n",
    "                \"strides\":layer.strides,\n",
    "                \"padding\":layer.padding,\n",
    "                \"dilation\" : layer.dilation_rate,\n",
    "                \"groups\": layer.groups,\n",
    "                \"input shape\":tuple(layer.input.shape),\n",
    "                \"output shape\":tuple(layer.output.shape),\n",
    "                \"output dtype\": layer.dtype,\n",
    "                \"compute dtype\": layer.compute_dtype,\n",
    "                \"workload\" : \"conv2d\",\n",
    "                #\"other\":layer.get_config()\n",
    "            }\n",
    "        elif isinstance(layer, keras.layers.SeparableConv2D):\n",
    "            sep_conv[model.name+\":\"+layer.name] = {\n",
    "                \"filters\": layer.filters,\n",
    "                \"depth multiplier\": layer.depth_multiplier,\n",
    "                \"kernel\": layer.kernel_size,\n",
    "                \"strides\":layer.strides,\n",
    "                \"padding\":layer.padding,\n",
    "                \"dilation\" : layer.dilation_rate,\n",
    "                \"groups\": layer.groups,\n",
    "                \"input shape\":tuple(layer.input.shape),\n",
    "                \"output shape\":tuple(layer.output.shape),\n",
    "                \"output dtype\": layer.dtype,\n",
    "                \"compute dtype\": layer.compute_dtype,\n",
    "                \"workload\" : \"sep_conv2d\",\n",
    "                #\"other\":layer.get_config()\n",
    "            }\n",
    "        elif isinstance(layer, keras.layers.Dense):\n",
    "            dense[model.name+\":\"+layer.name] = {\n",
    "                \"units\": layer.units,\n",
    "                \"input shape\":tuple(layer.input.shape),\n",
    "                \"output shape\":tuple(layer.output.shape),\n",
    "                \"output dtype\": layer.dtype,\n",
    "                \"compute dtype\": layer.compute_dtype,\n",
    "                \"workload\" : \"dense\",\n",
    "                #\"other\":layer.get_config()\n",
    "            }\n",
    "        elif isinstance(layer, keras.layers.MaxPooling2D):\n",
    "            max_pool[model.name+\":\"+layer.name] = {\n",
    "                \"pool_size\":layer.pool_size,\n",
    "                \"strides\":layer.strides,\n",
    "                \"padding\":layer.padding,\n",
    "                \"input shape\":tuple(layer.input.shape),\n",
    "                \"output shape\":tuple(layer.output.shape),\n",
    "                \"output dtype\": layer.dtype,\n",
    "                \"compute dtype\": layer.compute_dtype,\n",
    "                \"workload\" : \"max_pool2d\",\n",
    "                #\"other\":layer.get_config()\n",
    "            }\n",
    "        elif isinstance(layer, keras.layers.AveragePooling2D):\n",
    "            avg_pool[model.name+\":\"+layer.name] = {\n",
    "                \"pool_size\":layer.pool_size,\n",
    "                \"strides\":layer.strides,\n",
    "                \"padding\":layer.padding,\n",
    "                \"input shape\":tuple(layer.input.shape),\n",
    "                \"output shape\":tuple(layer.output.shape),\n",
    "                \"output dtype\": layer.dtype,\n",
    "                \"compute dtype\": layer.compute_dtype,\n",
    "                \"workload\" : \"avg_pool2d\",\n",
    "                #\"other\":layer.get_config()\n",
    "            }\n",
    "        else:\n",
    "            #print(\"unknown layer:\",idx, layer.name, type(layer))\n",
    "            unknown[model.name+\":\"+layer.name] = type(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208caed1-068f-4da8-b8e6-1324c9a790cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(conv)\n",
    "filter_sizes = set()\n",
    "kernel_sizes = set()\n",
    "stride_sizes = set()\n",
    "padding_configs = set()\n",
    "dilation_sizes = set()\n",
    "group_sizes = set()\n",
    "for name, config in conv.items():\n",
    "    #print(name)\n",
    "    filter_sizes.add(config[\"filters\"])\n",
    "    kernel_sizes.add(config[\"kernel\"][0])\n",
    "    stride_sizes.add(config[\"strides\"][0])\n",
    "    dilation_sizes.add(config[\"dilation\"][0])\n",
    "    group_sizes.add(config[\"groups\"])\n",
    "    padding_configs.add(config[\"padding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5a2c0f-6e44-493a-8e9f-9dee35dd9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_txt = json.dumps(conv)\n",
    "with open(\"conv_layer_config.json\", \"w\") as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580acc12-4c06-46f4-b040-c339a93cb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_txt = json.dumps(sep_conv)\n",
    "with open(\"sep_conv_layer_config.json\", \"w\") as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb5c0c98-5d9c-4810-bb0a-7fc20b267c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_txt = json.dumps(dense)\n",
    "with open(\"dense_layer_config.json\", \"w\") as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c946f193-b938-4ee7-a3f2-9f35da7a9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_txt = json.dumps(max_pool)\n",
    "with open(\"max_pool_layer_config.json\", \"w\") as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051693cd-8678-4dfc-8d1d-0753473faf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_txt = json.dumps(avg_pool)\n",
    "with open(\"avg_pool_layer_config.json\", \"w\") as file:\n",
    "    file.write(json_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abd6078-e8bd-4d24-85dd-8a7426ccbc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2627"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = {}\n",
    "max_pool = {}\n",
    "avg_pool = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
